{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This uses the BCI Comp III, Dataset # 2 from a P300 speller http://www.bbci.de/competition/iii/desc_II.pdf\n",
    "\n",
    "The winning accuracy was 96.5% for sampling of 15 trials and 73.5% for 5 trials http://www.bbci.de/competition/iii/results/#winners\n",
    "\n",
    "\n",
    "Continuing on example found at https://github.com/venthur/wyrm/blob/master/examples/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egorkharakozov/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "from wyrm import plot\n",
    "plot.beautify()\n",
    "from wyrm.types import Data\n",
    "from wyrm import processing as proc\n",
    "from wyrm.io import load_bcicomp3_ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Train.mat'\n",
    "TRAIN_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Train.mat'\n",
    "\n",
    "TEST_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Test.mat'\n",
    "TEST_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Test.mat'\n",
    "\n",
    "TRUE_LABELS_A = 'WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU'\n",
    "TRUE_LABELS_B = 'MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR'\n",
    "\n",
    "MATRIX = ['abcdef',\n",
    "          'ghijkl',\n",
    "          'mnopqr',\n",
    "          'stuvwx',\n",
    "          'yz1234',\n",
    "          '56789_']\n",
    "\n",
    "MARKER_DEF_TRAIN = {'target': ['target'], 'nontarget': ['nontarget']}\n",
    "MARKER_DEF_TEST = {'flashing': ['flashing']}\n",
    "\n",
    "SEG_IVAL = [0, 700]\n",
    "\n",
    "JUMPING_MEANS_IVALS_A = [150, 220], [200, 260], [310, 360], [550, 660] # 91%\n",
    "JUMPING_MEANS_IVALS_B = [150, 250], [200, 280], [280, 380], [480, 610] # 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing_simple(dat, MRK_DEF, *args, **kwargs):\n",
    "    \"\"\"Simple preprocessing that reaches 97% accuracy.\n",
    "    \"\"\"\n",
    "    fs_n = dat.fs / 2\n",
    "    b, a = proc.signal.butter(5, [10 / fs_n], btype='low')\n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "   \n",
    "    dat = proc.subsample(dat, 20)\n",
    "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
    "    fv = proc.create_feature_vectors(epo)\n",
    "    return fv, epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(dat, MRK_DEF, JUMPING_MEANS_IVALS):\n",
    "    dat = proc.sort_channels(dat)\n",
    "    \n",
    "    fs_n = dat.fs / 2\n",
    "    b, a = proc.signal.butter(5, [30 / fs_n], btype='low')\n",
    "    dat = proc.lfilter(dat, b, a)\n",
    "    b, a = proc.signal.butter(5, [.4 / fs_n], btype='high')\n",
    "    dat = proc.lfilter(dat, b, a)\n",
    "    \n",
    "    dat = proc.subsample(dat, 60)\n",
    "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
    "    \n",
    "    fv = proc.jumping_means(epo, JUMPING_MEANS_IVALS)\n",
    "    fv = proc.create_feature_vectors(fv)\n",
    "    return fv, epo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target accuracy using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result for subject 1\n",
      "Constructed labels: WQXPLZCOMRKOW7YFZDEZ1DPI9NN2GRKDJCUJRMEUOCOJD2UFYPOO6J7LDGYEGOA5VHNEKBW4OO1TDOILUEE5BFAEEXAW_K3R3MRU\n",
      "True labels       : WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU\n",
      "Accuracy: 91.0%\n",
      "\n",
      "Result for subject 2\n",
      "Constructed labels: MERMIROOMUZJPXJOHUVFBORZP3GLOO7AUFDKEFTWEOOALZOP9R1CGZE11Y19EWX65QUYU7NAK_1ACJDVDNGQXOJBEV2B5EFDIDTR\n",
      "True labels       : MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR\n",
      "Accuracy: 91.0%\n",
      "\n",
      "Overal accuracy: 91.0%\n"
     ]
    }
   ],
   "source": [
    "epo = [None, None]\n",
    "acc = 0\n",
    "for subject in range(2):\n",
    "    if subject == 0:\n",
    "        training_set = TRAIN_A\n",
    "        testing_set = TEST_A\n",
    "        labels = TRUE_LABELS_A\n",
    "        jumping_means_ivals = JUMPING_MEANS_IVALS_A\n",
    "    else:\n",
    "        training_set = TRAIN_B\n",
    "        testing_set = TEST_B\n",
    "        labels = TRUE_LABELS_B\n",
    "        jumping_means_ivals = JUMPING_MEANS_IVALS_B\n",
    "    \n",
    "    # load the training set\n",
    "    dat = load_bcicomp3_ds2(training_set)\n",
    "    fv_train, epo[subject] = preprocessing(dat, MARKER_DEF_TRAIN, jumping_means_ivals)\n",
    "    \n",
    "    # train the lda\n",
    "    cfy = proc.lda_train(fv_train)\n",
    "    \n",
    "    # load the testing set\n",
    "    dat = load_bcicomp3_ds2(testing_set)\n",
    "    fv_test, _ = preprocessing(dat, MARKER_DEF_TEST, jumping_means_ivals)\n",
    "    \n",
    "    # predict\n",
    "    lda_out_prob = proc.lda_apply(fv_test, cfy)\n",
    "    \n",
    "    # unscramble the order of stimuli\n",
    "    unscramble_idx = fv_test.stimulus_code.reshape(100, 15, 12).argsort()\n",
    "    static_idx = np.indices(unscramble_idx.shape)\n",
    "    lda_out_prob = lda_out_prob.reshape(100, 15, 12)\n",
    "    lda_out_prob = lda_out_prob[static_idx[0], static_idx[1], unscramble_idx]\n",
    "    \n",
    "    #lda_out_prob = lda_out_prob[:, :5, :]\n",
    "    \n",
    "    # destil the result of the 15 runs\n",
    "    #lda_out_prob = lda_out_prob.prod(axis=1)\n",
    "    lda_out_prob = lda_out_prob.sum(axis=1)\n",
    "        \n",
    "    # \n",
    "    lda_out_prob = lda_out_prob.argsort()\n",
    "    \n",
    "    cols = lda_out_prob[lda_out_prob <= 5].reshape(100, -1)\n",
    "    rows = lda_out_prob[lda_out_prob > 5].reshape(100, -1)\n",
    "    text = ''\n",
    "    for i in range(100):\n",
    "        row = rows[i][-1]-6\n",
    "        col = cols[i][-1]\n",
    "        letter = MATRIX[row][col]\n",
    "        text += letter\n",
    "    print\n",
    "    print 'Result for subject %d' % (subject+1)\n",
    "    print 'Constructed labels: %s' % text.upper()\n",
    "    print 'True labels       : %s' % labels\n",
    "    a = np.array(list(text.upper()))\n",
    "    b = np.array(list(labels))\n",
    "    accuracy = np.count_nonzero(a == b) / len(a)\n",
    "    print 'Accuracy: %.1f%%' % (accuracy * 100)\n",
    "    acc += accuracy\n",
    "print\n",
    "print 'Overal accuracy: %.1f%%' % (100 * acc / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using a Multi Layer Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.constraints import maxnorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Network Description\n",
    "\n",
    "Looks like a shallow network topology so far gets the best results of around 84%. Which is not bad and would have been close to the top 5 results in the original competition. As a next step I will use cross validation and see how the accuracy and fit diverge on the training and validation portions to see if perhaps more epochs are needed to train further.\n",
    "\n",
    "Network topology:\n",
    "[256 inputs with 20% dropout] -->  [64 neuron hidden rectifier layer with 30% dropout] --> [1 output sigmoid neuron]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(256,)))\n",
    "    model.add(Dense(64, init='normal', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, momentum=0.9, decay=0.001, nesterov=False)\n",
    "    \n",
    "    # Compile model\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy']) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = .9\n",
    "    drop = 0.5\n",
    "    epochs_drop = 1\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build pipeline with standartization \n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model, nb_epoch=500,\n",
    "    batch_size=30, verbose=0)))\n",
    "pipeline = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result for subject 1\n",
      "Constructed labels: WQXDLZCOMRKUK7YFYDEZ1DQJ9NN2GR_DKUUJRMEUCCOJD2UFYPOOKJ7LDGYEGOA5VXNEHBU4OO1TDOILUEE5BAAEEXAWRK2R3MRU\n",
      "True labels       : WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU\n",
      "Accuracy: 80.0%\n",
      "\n",
      "Result for subject 2\n",
      "Constructed labels: MERMIMOOMUHJPXJOHUPKDORHL3GLOO7DUFDKFFTWEOOALZOP9R1CGZEY1Y19EWX65QUYU7NAK_4ACDDVDNAQXODBEV2B5EFDIDNR\n",
      "True labels       : MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR\n",
      "Accuracy: 87.0%\n",
      "\n",
      "Overal accuracy: 83.5%\n"
     ]
    }
   ],
   "source": [
    "epo = [None, None]\n",
    "acc = 0\n",
    "for subject in range(2):\n",
    "    if subject == 0:\n",
    "        training_set = TRAIN_A\n",
    "        testing_set = TEST_A\n",
    "        labels = TRUE_LABELS_A\n",
    "        jumping_means_ivals = JUMPING_MEANS_IVALS_A\n",
    "    else:\n",
    "        training_set = TRAIN_B\n",
    "        testing_set = TEST_B\n",
    "        labels = TRUE_LABELS_B\n",
    "        jumping_means_ivals = JUMPING_MEANS_IVALS_B\n",
    "    \n",
    "    # load the training set\n",
    "    dat = load_bcicomp3_ds2(training_set)\n",
    "    fv_train, epo[subject] = preprocessing(dat, MARKER_DEF_TRAIN, jumping_means_ivals)\n",
    "    \n",
    "    # train the MLP\n",
    "    pipeline.fit(fv_train.data, fv_train.axes[0])\n",
    "    \n",
    "    # load the testing set\n",
    "    dat = load_bcicomp3_ds2(testing_set)\n",
    "    fv_test, _ = preprocessing(dat, MARKER_DEF_TEST, jumping_means_ivals)\n",
    "    \n",
    "    # predict\n",
    "    mlp_out_prob = pipeline.predict_proba(fv_test.data)\n",
    "    \n",
    "    # unscramble the order of stimuli\n",
    "    unscramble_idx = fv_test.stimulus_code.reshape(100, 15, 12).argsort()\n",
    "    static_idx = np.indices(unscramble_idx.shape)\n",
    "    mlp_out_prob = mlp_out_prob[:,1].reshape(100, 15, 12)\n",
    "    mlp_out_prob = mlp_out_prob[static_idx[0], static_idx[1], unscramble_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # destil the result of the 15 runs\n",
    "    \n",
    "    mlp_out_prob = mlp_out_prob.sum(axis=1)\n",
    "        \n",
    "    # \n",
    "    mlp_out_prob = mlp_out_prob.argsort()\n",
    "    \n",
    "    cols = mlp_out_prob[mlp_out_prob <= 5].reshape(100, -1)\n",
    "    rows = mlp_out_prob[mlp_out_prob > 5].reshape(100, -1)\n",
    "    text = ''\n",
    "    for i in range(100):\n",
    "        row = rows[i][-1]-6\n",
    "        col = cols[i][-1]\n",
    "        letter = MATRIX[row][col]\n",
    "        text += letter\n",
    "    print\n",
    "    print 'Result for subject %d' % (subject+1)\n",
    "    print 'Constructed labels: %s' % text.upper()\n",
    "    print 'True labels       : %s' % labels\n",
    "    a = np.array(list(text.upper()))\n",
    "    b = np.array(list(labels))\n",
    "    accuracy = np.count_nonzero(a == b) / len(a)\n",
    "    print 'Accuracy: %.1f%%' % (accuracy * 100)\n",
    "    acc += accuracy\n",
    "print\n",
    "print 'Overal accuracy: %.1f%%' % (100 * acc / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
